# 메인 파이프라인 - 모든 로그를 받아서 처리
input {
  tcp {
    port => 5000
    codec => json_lines
    tags => ["tcp_input"]
  }

  syslog {
    port => 5514
    tags => ["syslog"]
  }

  http {
    port => 8080
    codec => json
    tags => ["http_input"]
  }
}

filter {
  # 타임스탬프 파싱
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }

  # 로그 레벨 정규화
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  }

  # JSON 파싱
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      tag_on_failure => ["_jsonparsefailure"]
    }
  }

  # Grok 패턴으로 일반적인 로그 포맷 파싱
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:logger} - %{GREEDYDATA:msg}" 
    }
    tag_on_failure => ["_grokparsefailure"]
  }

  # 호스트 정보 추가
  mutate {
    add_field => { "[@metadata][target_index]" => "logstash-general-%{+YYYY.MM.dd}" }
  }

  # 불필요한 필드 제거
  mutate {
    remove_field => [ "host", "port", "@version" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][target_index]}"
    template_name => "logstash-general"
    template_pattern => "logstash-general-*"
    template => {
      "index_patterns" => ["logstash-general-*"]
      "settings" => {
        "number_of_shards" => 1
        "number_of_replicas" => 0
        "index.refresh_interval" => "30s"
      }
    }
  }

  # 디버깅용 stdout (개발 환경에서만 사용)
  # stdout { codec => rubydebug }
}