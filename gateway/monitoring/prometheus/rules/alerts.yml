# Meritz Gateway 알림 규칙
# 시스템 및 서비스 모니터링을 위한 알림 설정

groups:
  # 시스템 리소스 알림
  - name: system-alerts
    rules:
      # 높은 CPU 사용률
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "높은 CPU 사용률 감지"
          description: "{{ $labels.instance }}에서 CPU 사용률이 {{ $value }}%로 5분간 80% 이상입니다."

      # 높은 메모리 사용률
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "높은 메모리 사용률 감지"
          description: "{{ $labels.instance }}에서 메모리 사용률이 {{ $value }}%로 5분간 80% 이상입니다."

      # 디스크 공간 부족
      - alert: DiskSpaceLow
        expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 85
        for: 2m
        labels:
          severity: critical
          service: system
        annotations:
          summary: "디스크 공간 부족"
          description: "{{ $labels.instance }}의 {{ $labels.mountpoint }}에서 디스크 사용률이 {{ $value }}%입니다."

      # 디스크 I/O 대기시간 증가
      - alert: HighDiskIOWait
        expr: rate(node_cpu_seconds_total{mode="iowait"}[5m]) * 100 > 20
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "높은 디스크 I/O 대기시간"
          description: "{{ $labels.instance }}에서 I/O 대기시간이 {{ $value }}%로 증가했습니다."

  # Traefik 게이트웨이 알림
  - name: traefik-alerts
    rules:
      # Traefik 서비스 다운
      - alert: TraefikDown
        expr: up{job="traefik"} == 0
        for: 1m
        labels:
          severity: critical
          service: traefik
        annotations:
          summary: "Traefik 게이트웨이 서비스 다운"
          description: "Traefik 게이트웨이가 {{ $value }} 분간 응답하지 않습니다."

      # 높은 응답 시간
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, sum(rate(traefik_http_request_duration_seconds_bucket[5m])) by (le)) > 1
        for: 5m
        labels:
          severity: warning
          service: traefik
        annotations:
          summary: "높은 HTTP 응답 시간"
          description: "Traefik의 95% 응답시간이 {{ $value }}초로 1초를 초과했습니다."

      # 높은 에러율
      - alert: HighErrorRate
        expr: (sum(rate(traefik_http_requests_total{code=~"5.."}[5m])) / sum(rate(traefik_http_requests_total[5m]))) * 100 > 5
        for: 5m
        labels:
          severity: critical
          service: traefik
        annotations:
          summary: "높은 HTTP 에러율"
          description: "지난 5분간 HTTP 5xx 에러율이 {{ $value }}%로 5%를 초과했습니다."

      # SSL 인증서 만료 임박
      - alert: SSLCertificateExpiringSoon
        expr: (x509_cert_not_after - time()) / 86400 < 30
        for: 1h
        labels:
          severity: warning
          service: ssl
        annotations:
          summary: "SSL 인증서 만료 임박"
          description: "{{ $labels.domain }}의 SSL 인증서가 {{ $value }}일 후 만료됩니다."

  # 컨테이너 알림
  - name: container-alerts
    rules:
      # 컨테이너 다운
      - alert: ContainerDown
        expr: up{job="cadvisor"} == 0
        for: 1m
        labels:
          severity: critical
          service: container
        annotations:
          summary: "컨테이너 모니터링 서비스 다운"
          description: "cAdvisor 컨테이너 모니터링 서비스가 응답하지 않습니다."

      # 컨테이너 높은 메모리 사용률
      - alert: ContainerHighMemoryUsage
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: container
        annotations:
          summary: "컨테이너 높은 메모리 사용률"
          description: "{{ $labels.name }} 컨테이너의 메모리 사용률이 {{ $value }}%입니다."

      # 컨테이너 재시작 빈발
      - alert: ContainerHighRestartRate
        expr: increase(container_restart_count[1h]) > 5
        for: 0m
        labels:
          severity: warning
          service: container
        annotations:
          summary: "컨테이너 재시작 빈발"
          description: "{{ $labels.name }} 컨테이너가 지난 1시간 동안 {{ $value }}회 재시작되었습니다."

  # 서비스별 알림
  - name: service-alerts
    rules:
      # Prometheus 다운
      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 1m
        labels:
          severity: critical
          service: prometheus
        annotations:
          summary: "Prometheus 서비스 다운"
          description: "Prometheus 모니터링 서비스가 응답하지 않습니다."

      # Grafana 다운
      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 1m
        labels:
          severity: warning
          service: grafana
        annotations:
          summary: "Grafana 서비스 다운"
          description: "Grafana 대시보드 서비스가 응답하지 않습니다."

      # Loki 다운
      - alert: LokiDown
        expr: up{job="loki"} == 0
        for: 1m
        labels:
          severity: warning
          service: loki
        annotations:
          summary: "Loki 로그 서비스 다운"
          description: "Loki 로그 수집 서비스가 응답하지 않습니다."

  # 네트워크 알림
  - name: network-alerts
    rules:
      # 높은 네트워크 사용률
      - alert: HighNetworkUsage
        expr: rate(node_network_receive_bytes_total[5m]) + rate(node_network_transmit_bytes_total[5m]) > 100000000
        for: 5m
        labels:
          severity: warning
          service: network
        annotations:
          summary: "높은 네트워크 사용률"
          description: "{{ $labels.instance }}의 {{ $labels.device }}에서 네트워크 사용률이 {{ $value }} bytes/sec입니다."

      # 네트워크 에러 증가
      - alert: NetworkErrors
        expr: rate(node_network_receive_errs_total[5m]) + rate(node_network_transmit_errs_total[5m]) > 10
        for: 2m
        labels:
          severity: warning
          service: network
        annotations:
          summary: "네트워크 에러 증가"
          description: "{{ $labels.instance }}의 {{ $labels.device }}에서 네트워크 에러가 {{ $value }}/sec 발생하고 있습니다."

  # 로그 기반 알림
  - name: log-alerts
    rules:
      # 높은 에러 로그 발생률
      - alert: HighErrorLogRate
        expr: rate(loki_log_entries_total{level="error"}[5m]) > 1
        for: 2m
        labels:
          severity: warning
          service: logging
        annotations:
          summary: "높은 에러 로그 발생률"
          description: "지난 5분간 에러 로그가 {{ $value }}/sec 발생하고 있습니다."

      # 로그 수집 지연
      - alert: LogIngestionLag
        expr: time() - timestamp(loki_ingester_memory_chunks_created_total) > 300
        for: 5m
        labels:
          severity: warning
          service: logging
        annotations:
          summary: "로그 수집 지연"
          description: "로그 수집이 {{ $value }}초 지연되고 있습니다."
